{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import torch\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6161, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Headquarters</th>\n",
       "      <th>Size</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Competitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>$111K-$181K (Glassdoor est.)</td>\n",
       "      <td>ABOUT HOPPER\\n\\nAt Hopper, we’re on a mission ...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Hopper\\n3.5</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Montreal, Canada</td>\n",
       "      <td>501 to 1000 employees</td>\n",
       "      <td>2007</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Travel Agencies</td>\n",
       "      <td>Travel &amp; Tourism</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist, Product Analytics</td>\n",
       "      <td>$111K-$181K (Glassdoor est.)</td>\n",
       "      <td>At Noom, we use scientifically proven methods ...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Noom US\\n4.5</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1001 to 5000 employees</td>\n",
       "      <td>2008</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Health, Beauty, &amp; Fitness</td>\n",
       "      <td>Consumer Services</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>$111K-$181K (Glassdoor est.)</td>\n",
       "      <td>Decode_M\\n\\nhttps://www.decode-m.com/\\n\\nData ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Decode_M</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1 to 50 employees</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>$111K-$181K (Glassdoor est.)</td>\n",
       "      <td>Sapphire Digital seeks a dynamic and driven mi...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Sapphire Digital\\n3.4</td>\n",
       "      <td>Lyndhurst, NJ</td>\n",
       "      <td>Lyndhurst, NJ</td>\n",
       "      <td>201 to 500 employees</td>\n",
       "      <td>2019</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>Zocdoc, Healthgrades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Director, Data Science</td>\n",
       "      <td>$111K-$181K (Glassdoor est.)</td>\n",
       "      <td>Director, Data Science - (200537)\\nDescription...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>United Entertainment Group\\n3.4</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>51 to 200 employees</td>\n",
       "      <td>2007</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Advertising &amp; Marketing</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>BBDO, Grey Group, Droga5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Job Title               Salary Estimate  \\\n",
       "0              Senior Data Scientist  $111K-$181K (Glassdoor est.)   \n",
       "1  Data Scientist, Product Analytics  $111K-$181K (Glassdoor est.)   \n",
       "2               Data Science Manager  $111K-$181K (Glassdoor est.)   \n",
       "3                       Data Analyst  $111K-$181K (Glassdoor est.)   \n",
       "4             Director, Data Science  $111K-$181K (Glassdoor est.)   \n",
       "\n",
       "                                     Job Description  Rating  \\\n",
       "0  ABOUT HOPPER\\n\\nAt Hopper, we’re on a mission ...     3.5   \n",
       "1  At Noom, we use scientifically proven methods ...     4.5   \n",
       "2  Decode_M\\n\\nhttps://www.decode-m.com/\\n\\nData ...    -1.0   \n",
       "3  Sapphire Digital seeks a dynamic and driven mi...     3.4   \n",
       "4  Director, Data Science - (200537)\\nDescription...     3.4   \n",
       "\n",
       "                      Company Name       Location      Headquarters  \\\n",
       "0                      Hopper\\n3.5   New York, NY  Montreal, Canada   \n",
       "1                     Noom US\\n4.5   New York, NY      New York, NY   \n",
       "2                         Decode_M   New York, NY      New York, NY   \n",
       "3            Sapphire Digital\\n3.4  Lyndhurst, NJ     Lyndhurst, NJ   \n",
       "4  United Entertainment Group\\n3.4   New York, NY      New York, NY   \n",
       "\n",
       "                     Size  Founded  Type of ownership  \\\n",
       "0   501 to 1000 employees     2007  Company - Private   \n",
       "1  1001 to 5000 employees     2008  Company - Private   \n",
       "2       1 to 50 employees       -1            Unknown   \n",
       "3    201 to 500 employees     2019  Company - Private   \n",
       "4     51 to 200 employees     2007  Company - Private   \n",
       "\n",
       "                    Industry                  Sector  \\\n",
       "0            Travel Agencies        Travel & Tourism   \n",
       "1  Health, Beauty, & Fitness       Consumer Services   \n",
       "2                         -1                      -1   \n",
       "3                   Internet  Information Technology   \n",
       "4    Advertising & Marketing       Business Services   \n",
       "\n",
       "                    Revenue               Competitors  \n",
       "0  Unknown / Non-Applicable                        -1  \n",
       "1  Unknown / Non-Applicable                        -1  \n",
       "2  Unknown / Non-Applicable                        -1  \n",
       "3  Unknown / Non-Applicable      Zocdoc, Healthgrades  \n",
       "4  Unknown / Non-Applicable  BBDO, Grey Group, Droga5  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Dataset/DataScientist.csv')\n",
    "df2 = pd.read_csv('Dataset/DataAnalyst.csv')\n",
    "df = df.drop(columns=['index'])\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df2 = df2.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df_final = pd.concat([df, df2], ignore_index=True).drop_duplicates()\n",
    "df_final = df_final.drop(columns=['Easy Apply'])\n",
    "print(df_final.shape)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Description\n",
      "<class 'str'>    6161\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_final['Job Description'].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Headquarters</th>\n",
       "      <th>Size</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Competitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>$111K-$181K (Glassdoor est.)</td>\n",
       "      <td>hopper hopper mission make booking travel fast...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>hopper</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Montreal, Canada</td>\n",
       "      <td>501 to 1000 employees</td>\n",
       "      <td>2007</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Travel Agencies</td>\n",
       "      <td>Travel &amp; Tourism</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist, Product Analytics</td>\n",
       "      <td>$111K-$181K (Glassdoor est.)</td>\n",
       "      <td>noom use scientifically proven method help use...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>noom u</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1001 to 5000 employees</td>\n",
       "      <td>2008</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Health, Beauty, &amp; Fitness</td>\n",
       "      <td>Consumer Services</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>$111K-$181K (Glassdoor est.)</td>\n",
       "      <td>decodem data science manager job description h...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>decodem</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1 to 50 employees</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>$111K-$181K (Glassdoor est.)</td>\n",
       "      <td>sapphire digital seek dynamic driven midlevel ...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>sapphire digital</td>\n",
       "      <td>Lyndhurst, NJ</td>\n",
       "      <td>Lyndhurst, NJ</td>\n",
       "      <td>201 to 500 employees</td>\n",
       "      <td>2019</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>Zocdoc, Healthgrades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Director, Data Science</td>\n",
       "      <td>$111K-$181K (Glassdoor est.)</td>\n",
       "      <td>director data science description edelman inte...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>united entertainment group</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>51 to 200 employees</td>\n",
       "      <td>2007</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Advertising &amp; Marketing</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>BBDO, Grey Group, Droga5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Job Title               Salary Estimate  \\\n",
       "0              Senior Data Scientist  $111K-$181K (Glassdoor est.)   \n",
       "1  Data Scientist, Product Analytics  $111K-$181K (Glassdoor est.)   \n",
       "2               Data Science Manager  $111K-$181K (Glassdoor est.)   \n",
       "3                       Data Analyst  $111K-$181K (Glassdoor est.)   \n",
       "4             Director, Data Science  $111K-$181K (Glassdoor est.)   \n",
       "\n",
       "                                     Job Description  Rating  \\\n",
       "0  hopper hopper mission make booking travel fast...     3.5   \n",
       "1  noom use scientifically proven method help use...     4.5   \n",
       "2  decodem data science manager job description h...    -1.0   \n",
       "3  sapphire digital seek dynamic driven midlevel ...     3.4   \n",
       "4  director data science description edelman inte...     3.4   \n",
       "\n",
       "                 Company Name       Location      Headquarters  \\\n",
       "0                      hopper   New York, NY  Montreal, Canada   \n",
       "1                      noom u   New York, NY      New York, NY   \n",
       "2                     decodem   New York, NY      New York, NY   \n",
       "3            sapphire digital  Lyndhurst, NJ     Lyndhurst, NJ   \n",
       "4  united entertainment group   New York, NY      New York, NY   \n",
       "\n",
       "                     Size  Founded  Type of ownership  \\\n",
       "0   501 to 1000 employees     2007  Company - Private   \n",
       "1  1001 to 5000 employees     2008  Company - Private   \n",
       "2       1 to 50 employees       -1            Unknown   \n",
       "3    201 to 500 employees     2019  Company - Private   \n",
       "4     51 to 200 employees     2007  Company - Private   \n",
       "\n",
       "                    Industry                  Sector  \\\n",
       "0            Travel Agencies        Travel & Tourism   \n",
       "1  Health, Beauty, & Fitness       Consumer Services   \n",
       "2                         -1                      -1   \n",
       "3                   Internet  Information Technology   \n",
       "4    Advertising & Marketing       Business Services   \n",
       "\n",
       "                    Revenue               Competitors  \n",
       "0  Unknown / Non-Applicable                        -1  \n",
       "1  Unknown / Non-Applicable                        -1  \n",
       "2  Unknown / Non-Applicable                        -1  \n",
       "3  Unknown / Non-Applicable      Zocdoc, Healthgrades  \n",
       "4  Unknown / Non-Applicable  BBDO, Grey Group, Droga5  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def nettoyer(text):\n",
    "  if isinstance(text, str):\n",
    "    text = text.lower()\n",
    "    # Supprimer les caractères spéciaux\n",
    "    text = re.sub(r'(http\\S+|[^a-zA-Z\\s])', '', text)\n",
    "    # Tokenisation\n",
    "    words = nltk.word_tokenize(text)\n",
    "    # Suppression des mots vides et lemmatisation\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    text = ' '.join(words)\n",
    "    # Reconstituer le texte prétraité\n",
    "    return text\n",
    "  else:\n",
    "    return np.nan\n",
    "\n",
    "df_final['Job Description'] = df_final['Job Description'].apply(nettoyer)\n",
    "df_final['Company Name'] = df_final['Company Name'].apply(nettoyer)\n",
    "df_final['Revenue'].replace(-1, np.nan)\n",
    "df_final['Founded'].replace(-1, np.nan)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 14041\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 3250\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 3453\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "# Load the CoNLL-2003 dataset\n",
    "dataset = load_dataset(\"conll2003\",trust_remote_code=True)\n",
    "print(dataset)\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
      "NER Tags: [3, 0, 7, 0, 0, 0, 7, 0, 0]\n",
      "Tokens: ['Peter', 'Blackburn']\n",
      "NER Tags: [1, 2]\n",
      "Tokens: ['BRUSSELS', '1996-08-22']\n",
      "NER Tags: [5, 0]\n",
      "Tokens: ['The', 'European', 'Commission', 'said', 'on', 'Thursday', 'it', 'disagreed', 'with', 'German', 'advice', 'to', 'consumers', 'to', 'shun', 'British', 'lamb', 'until', 'scientists', 'determine', 'whether', 'mad', 'cow', 'disease', 'can', 'be', 'transmitted', 'to', 'sheep', '.']\n",
      "NER Tags: [0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Tokens: ['Germany', \"'s\", 'representative', 'to', 'the', 'European', 'Union', \"'s\", 'veterinary', 'committee', 'Werner', 'Zwingmann', 'said', 'on', 'Wednesday', 'consumers', 'should', 'buy', 'sheepmeat', 'from', 'countries', 'other', 'than', 'Britain', 'until', 'the', 'scientific', 'advice', 'was', 'clearer', '.']\n",
      "NER Tags: [5, 0, 0, 0, 0, 3, 4, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Check dataset structure\n",
    "for i in range(5):  # Check a few samples\n",
    "    print(\"Tokens:\", dataset[\"train\"][\"tokens\"][i])\n",
    "    print(\"NER Tags:\", dataset[\"train\"][\"ner_tags\"][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForTokenClassification\n",
    "\n",
    "# Define the label map\n",
    "label_list = [\"O\", \"B-PER\", \"I-PER\", \"B-LOC\", \"I-LOC\", \"B-ORG\", \"I-ORG\"]\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels_fixed_length(dataset, tokenizer=tokenizer, max_length=50):\n",
    "    # Tokenize the input text with truncation and padding to a fixed length\n",
    "    tokenized_inputs = tokenizer(\n",
    "        dataset[\"tokens\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        is_split_into_words=True,\n",
    "        return_overflowing_tokens=False,  # Prevent splitting long sequences\n",
    "    )\n",
    "    \n",
    "    aligned_labels = []\n",
    "    for i, labels in enumerate(dataset[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to words\n",
    "        label_ids = []\n",
    "        previous_word_idx = None\n",
    "\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                # Special tokens (e.g., [CLS], [SEP], or padding)\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                # Assign label for the first sub-token of a word\n",
    "                label_ids.append(labels[word_idx])\n",
    "            else:\n",
    "                # Sub-token should be masked with -100\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        # Ensure labels are padded to max_length\n",
    "        if len(label_ids) < max_length:\n",
    "            label_ids += [-100] * (max_length - len(label_ids))\n",
    "        else:\n",
    "            label_ids = label_ids[:max_length]\n",
    "        \n",
    "        aligned_labels.append(label_ids)\n",
    "\n",
    "    # Update tokenized inputs with aligned labels\n",
    "    tokenized_inputs[\"labels\"] = aligned_labels\n",
    "\n",
    "    # Force all keys to have consistent lengths\n",
    "    for key in tokenized_inputs.keys():\n",
    "        if key in [\"input_ids\", \"attention_mask\", \"token_type_ids\"]:\n",
    "            tokenized_inputs[key] = [\n",
    "                seq[:max_length] + [0] * (max_length - len(seq)) if len(seq) < max_length else seq[:max_length]\n",
    "                for seq in tokenized_inputs[key]\n",
    "            ]\n",
    "    \n",
    "    return tokenized_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 14041/14041 [00:02<00:00, 6908.20 examples/s]\n",
      "Map: 100%|██████████| 3250/3250 [00:00<00:00, 6490.09 examples/s]\n",
      "Map: 100%|██████████| 3453/3453 [00:00<00:00, 6830.37 examples/s]\n"
     ]
    }
   ],
   "source": [
    "encoded_dataset = dataset.map(tokenize_and_align_labels_fixed_length, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
      "NER Tags: [3, 0, 7, 0, 0, 0, 7, 0, 0]\n",
      "Tokens: ['Peter', 'Blackburn']\n",
      "NER Tags: [1, 2]\n",
      "Tokens: ['BRUSSELS', '1996-08-22']\n",
      "NER Tags: [5, 0]\n",
      "Tokens: ['The', 'European', 'Commission', 'said', 'on', 'Thursday', 'it', 'disagreed', 'with', 'German', 'advice', 'to', 'consumers', 'to', 'shun', 'British', 'lamb', 'until', 'scientists', 'determine', 'whether', 'mad', 'cow', 'disease', 'can', 'be', 'transmitted', 'to', 'sheep', '.']\n",
      "NER Tags: [0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Tokens: ['Germany', \"'s\", 'representative', 'to', 'the', 'European', 'Union', \"'s\", 'veterinary', 'committee', 'Werner', 'Zwingmann', 'said', 'on', 'Wednesday', 'consumers', 'should', 'buy', 'sheepmeat', 'from', 'countries', 'other', 'than', 'Britain', 'until', 'the', 'scientific', 'advice', 'was', 'clearer', '.']\n",
      "NER Tags: [5, 0, 0, 0, 0, 3, 4, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Check dataset structure\n",
    "for i in range(5):  # Check a few samples\n",
    "    print(\"Tokens:\", encoded_dataset[\"train\"][\"tokens\"][i])\n",
    "    print(\"NER Tags:\", encoded_dataset[\"train\"][\"ner_tags\"][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    use_cpu=True,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Perform evaluation on the test set\n",
    "predictions, labels, _ = trainer.predict(test_data)\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Convert predictions and labels to their original format\n",
    "true_labels = [[label_list[l] for l in label if l != -100] for label in labels]\n",
    "predicted_labels = [[label_list[p] for p in pred if p != -100] for pred in predictions]\n",
    "\n",
    "# Flatten the lists for evaluation\n",
    "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
    "flat_predicted_labels = [item for sublist in predicted_labels for item in sublist]\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(flat_true_labels, flat_predicted_labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
